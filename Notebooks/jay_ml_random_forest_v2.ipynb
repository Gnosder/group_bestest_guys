{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Updated Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update sklearn to prevent version mismatches\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### install joblib. This will be used to save your model. \n",
    "### Restart your kernel after installing \n",
    "# !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>sum_sentiment_score</th>\n",
       "      <th>delta_avg</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>s&amp;p_%change</th>\n",
       "      <th>s&amp;p_up/down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.434286</td>\n",
       "      <td>76.08</td>\n",
       "      <td>-0.100675</td>\n",
       "      <td>10063</td>\n",
       "      <td>40673</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.963077</td>\n",
       "      <td>64.52</td>\n",
       "      <td>-0.571884</td>\n",
       "      <td>6982</td>\n",
       "      <td>30051</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.777143</td>\n",
       "      <td>80.88</td>\n",
       "      <td>0.242182</td>\n",
       "      <td>15421</td>\n",
       "      <td>54861</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.107143</td>\n",
       "      <td>71.50</td>\n",
       "      <td>-0.427818</td>\n",
       "      <td>15261</td>\n",
       "      <td>64289</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.060000</td>\n",
       "      <td>45.54</td>\n",
       "      <td>-0.474961</td>\n",
       "      <td>27885</td>\n",
       "      <td>105693</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  tweets  isRetweet  isDeleted  avg_sentiment_score  \\\n",
       "0  2016-12-08       1          0          0             5.434286   \n",
       "1  2016-12-15       1          0          0             4.963077   \n",
       "2  2017-01-06       1          0          0             5.777143   \n",
       "3  2017-01-09       1          0          0             5.107143   \n",
       "4  2017-01-12       1          0          0             5.060000   \n",
       "\n",
       "   sum_sentiment_score  delta_avg  retweets  favorites  word_count  positive  \\\n",
       "0                76.08  -0.100675     10063      40673          83         0   \n",
       "1                64.52  -0.571884      6982      30051          76         0   \n",
       "2                80.88   0.242182     15421      54861          82         1   \n",
       "3                71.50  -0.427818     15261      64289          79         0   \n",
       "4                45.54  -0.474961     27885     105693          51         0   \n",
       "\n",
       "   negative  neutral  s&p_%change s&p_up/down  \n",
       "0         0        1     0.002258          up  \n",
       "1         1        0     0.003665          up  \n",
       "2         0        0     0.002571          up  \n",
       "3         0        1    -0.002063        down  \n",
       "4         0        1    -0.000308        down  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/daily_summary_v2.csv')\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df = df.drop('index', axis=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Your Features and Label (X and y values)\n",
    "### With supervised learning, you have features and labels. The features are the descriptive attributes, and the label is what you're attempting to predict or forecast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>sum_sentiment_score</th>\n",
       "      <th>delta_avg</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.434286</td>\n",
       "      <td>76.08</td>\n",
       "      <td>-0.100675</td>\n",
       "      <td>10063</td>\n",
       "      <td>40673</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.963077</td>\n",
       "      <td>64.52</td>\n",
       "      <td>-0.571884</td>\n",
       "      <td>6982</td>\n",
       "      <td>30051</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.777143</td>\n",
       "      <td>80.88</td>\n",
       "      <td>0.242182</td>\n",
       "      <td>15421</td>\n",
       "      <td>54861</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.107143</td>\n",
       "      <td>71.50</td>\n",
       "      <td>-0.427818</td>\n",
       "      <td>15261</td>\n",
       "      <td>64289</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.060000</td>\n",
       "      <td>45.54</td>\n",
       "      <td>-0.474961</td>\n",
       "      <td>27885</td>\n",
       "      <td>105693</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweets  isRetweet  isDeleted  avg_sentiment_score  sum_sentiment_score  \\\n",
       "0       1          0          0             5.434286                76.08   \n",
       "1       1          0          0             4.963077                64.52   \n",
       "2       1          0          0             5.777143                80.88   \n",
       "3       1          0          0             5.107143                71.50   \n",
       "4       1          0          0             5.060000                45.54   \n",
       "\n",
       "   delta_avg  retweets  favorites  word_count  positive  negative  neutral  \n",
       "0  -0.100675     10063      40673          83         0         0        1  \n",
       "1  -0.571884      6982      30051          76         0         1        0  \n",
       "2   0.242182     15421      54861          82         1         0        0  \n",
       "3  -0.427818     15261      64289          79         0         0        1  \n",
       "4  -0.474961     27885     105693          51         0         0        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "# Select the features you would like to use - this is depended on the model you're going to use.\n",
    "# It might be benefitial to utilize a feature selection model.\n",
    "selected_features_all = df.drop(['date', 's&p_up/down', 's&p_%change'], axis=1)\n",
    "\n",
    "print(selected_features_all.shape)\n",
    "selected_features_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training And Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      up\n",
       "1      up\n",
       "2      up\n",
       "3    down\n",
       "4    down\n",
       "Name: s&p_up/down, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull out the output labels column or y values\n",
    "labels = df['s&p_up/down']\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train_test_split method to categorize your data into training and testing groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features_all, labels, train_size=.7, random_state=3)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(selected_features_all, labels, train_size=.7, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>sum_sentiment_score</th>\n",
       "      <th>delta_avg</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.566579</td>\n",
       "      <td>526.72</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>47458</td>\n",
       "      <td>163476</td>\n",
       "      <td>553</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.071263</td>\n",
       "      <td>202.78</td>\n",
       "      <td>-0.463698</td>\n",
       "      <td>39368</td>\n",
       "      <td>158046</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.586859</td>\n",
       "      <td>369.28</td>\n",
       "      <td>0.051899</td>\n",
       "      <td>41779</td>\n",
       "      <td>82344</td>\n",
       "      <td>378</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.664447</td>\n",
       "      <td>373.44</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>72249</td>\n",
       "      <td>322392</td>\n",
       "      <td>386</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>39.00</td>\n",
       "      <td>-0.659961</td>\n",
       "      <td>39420</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweets  isRetweet  isDeleted  avg_sentiment_score  sum_sentiment_score  \\\n",
       "523       9          7          0             5.566579               526.72   \n",
       "87        2          0          0             5.071263               202.78   \n",
       "382       5          3          0             5.586859               369.28   \n",
       "446       5          2          0             5.664447               373.44   \n",
       "518       1          1          0             4.875000                39.00   \n",
       "\n",
       "     delta_avg  retweets  favorites  word_count  positive  negative  neutral  \n",
       "523   0.031618     47458     163476         553         5         2        2  \n",
       "87   -0.463698     39368     158046         228         0         0        2  \n",
       "382   0.051899     41779      82344         378         4         0        1  \n",
       "446   0.129487     72249     322392         386         4         0        1  \n",
       "518  -0.659961     39420          0          48         0         1        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect training data\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61538462 0.58333333 0.         0.56437412 0.53776893 0.56437412\n",
      " 0.17005451 0.15256714 0.543      0.83333333 0.28571429 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# inspect the scaled data to see how the feature values have been scaled\n",
    "print(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm - Train The Model\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6524822695035462\n",
      "Testing Data Score: 0.6043956043956044\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier model for training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, bootstrap=True, max_depth=3, min_samples_split=8)\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8486997635933806\n",
      "Testing Data Score: 0.5054945054945055\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier model for training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10, bootstrap= True, max_depth= 10, min_samples_split= 8)\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the GridSearchCV model\n",
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid={'bootstrap': [True], 'n_estimators' : [10, 50, 100, 200],\n",
    "'min_samples_split' : range(8, 10, 20),'max_depth': [3, 10, 20, 40]}\n",
    "grid = GridSearchCV(clf, param_grid, verbose=3)\n",
    "\n",
    "# To get list of parameters you can tune\n",
    "clf.get_params().keys()\n",
    "# grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10, score=0.565, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10, score=0.553, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10, score=0.447, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10, score=0.429, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=10, score=0.500, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50, score=0.518, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50, score=0.529, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50, score=0.424, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50, score=0.488, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=50, score=0.488, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100, score=0.518, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100, score=0.494, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100, score=0.424, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100, score=0.512, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=100, score=0.500, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200, score=0.518, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200, score=0.529, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200, score=0.435, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200, score=0.524, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=3, min_samples_split=8, n_estimators=200, score=0.524, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10, score=0.471, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10, score=0.529, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10, score=0.518, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10, score=0.512, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=10, score=0.500, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50, score=0.424, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50, score=0.506, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50, score=0.424, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50, score=0.524, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=50, score=0.524, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100, score=0.412, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100, score=0.565, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100, score=0.376, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100, score=0.536, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=100, score=0.452, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200, score=0.494, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200, score=0.565, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200, score=0.447, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200, score=0.560, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=10, min_samples_split=8, n_estimators=200, score=0.476, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10, score=0.447, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10, score=0.506, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10, score=0.424, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10, score=0.500, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=10, score=0.464, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50, score=0.553, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50, score=0.553, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50, score=0.518, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50, score=0.560, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=50, score=0.560, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100, score=0.471, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100, score=0.494, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100, score=0.482, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100, score=0.548, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=100, score=0.488, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200, score=0.494, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200, score=0.541, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200, score=0.506, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200, score=0.548, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=20, min_samples_split=8, n_estimators=200, score=0.464, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10, score=0.553, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10, score=0.459, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10, score=0.529, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10, score=0.548, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=10, score=0.464, total=   0.0s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50, score=0.447, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50, score=0.529, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50, score=0.471, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50, score=0.524, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=50, score=0.464, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100, score=0.541, total=   0.2s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100, score=0.565, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100, score=0.482, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100, score=0.536, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=100, score=0.464, total=   0.1s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200, score=0.447, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200, score=0.600, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200, score=0.459, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200, score=0.548, total=   0.3s\n",
      "[CV] bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200 \n",
      "[CV]  bootstrap=True, max_depth=40, min_samples_split=8, n_estimators=200, score=0.464, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=10, min_samples_split=8,\n",
       "                                              n_estimators=10),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [3, 10, 20, 40],\n",
       "                         'min_samples_split': range(8, 10, 20),\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 20, 'min_samples_split': 8, 'n_estimators': 50}\n",
      "0.548515406162465\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model - No Tuning Or Feature Selection\n",
    "Training Data Score: 0.624113475177305\n",
    "\n",
    "Testing Data Score: 0.6263736263736264"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuned and Feature Selection Score\n",
    "\n",
    "Training Data Score: 0.5858585858585859\n",
    "\n",
    "Testing Data Score: 0.5268456375838926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_2_randomforest_extratreeclassifer.h5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'model_2_randomforest_extratreeclassifer.h5'\n",
    "joblib.dump(clf, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

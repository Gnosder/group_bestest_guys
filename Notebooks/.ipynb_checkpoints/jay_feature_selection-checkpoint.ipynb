{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "### Test different algorithmic functions to see which set of features will yeild better accuracy without overfitting the model. It will also reduce training time because of less data to process.\n",
    "#### Credit to Jason Brownlee's [article](https://machinelearningmastery.com/feature-selection-machine-learning-python/) for guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweets', 'isRetweet', 'isDeleted', 'avg_sentiment_score',\n",
      "       'sum_sentiment_score', 'delta_avg', 'retweets', 'favorites',\n",
      "       'word_count', 'positive', 'negative', 'neutral', 's&p_up/down'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>avg_sentiment_score</th>\n",
       "      <th>sum_sentiment_score</th>\n",
       "      <th>delta_avg</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>word_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>s&amp;p_up/down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.855472</td>\n",
       "      <td>915.44</td>\n",
       "      <td>0.099388</td>\n",
       "      <td>522435</td>\n",
       "      <td>1118266</td>\n",
       "      <td>908</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.599524</td>\n",
       "      <td>156.98</td>\n",
       "      <td>-0.156560</td>\n",
       "      <td>227982</td>\n",
       "      <td>700580</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.650000</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0.893916</td>\n",
       "      <td>36535</td>\n",
       "      <td>142625</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.826134</td>\n",
       "      <td>355.76</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>193625</td>\n",
       "      <td>832596</td>\n",
       "      <td>351</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.873654</td>\n",
       "      <td>146.84</td>\n",
       "      <td>0.117570</td>\n",
       "      <td>69857</td>\n",
       "      <td>254719</td>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweets  isRetweet  isDeleted  avg_sentiment_score  sum_sentiment_score  \\\n",
       "0      17          4          0             5.855472               915.44   \n",
       "1       3          1          0             5.599524               156.98   \n",
       "2       1          0          0             6.650000                39.90   \n",
       "3       5          0          0             5.826134               355.76   \n",
       "4       2          0          0             5.873654               146.84   \n",
       "\n",
       "   delta_avg  retweets  favorites  word_count  positive  negative  neutral  \\\n",
       "0   0.099388    522435    1118266         908        12         0        4   \n",
       "1  -0.156560    227982     700580         163         2         0        1   \n",
       "2   0.893916     36535     142625          32         1         0        0   \n",
       "3   0.070050    193625     832596         351         4         0        1   \n",
       "4   0.117570     69857     254719         144         2         0        0   \n",
       "\n",
       "  s&p_up/down  \n",
       "0          up  \n",
       "1          up  \n",
       "2        down  \n",
       "3          up  \n",
       "4          up  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the csv file\n",
    "df = pd.read_csv('../data/daily_summary.csv')\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "df = df.drop(['index', 'date', 's&p_%change'], axis=1)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array from the values in the dataframe values\n",
    "array = df.values\n",
    "# Pull out features and labels from the columns with slice \n",
    "X= array[:, :-1]\n",
    "y= array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df = pd.read_csv('../data/tweet_df_cleaned_w_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree Classifier\n",
    "Feature Importance with Bagged decision trees like Random Forest and Extra Trees can be used to esmiate the importance of features. \n",
    "\n",
    "Learn more about the [ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) class in the scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a scaled score of the features at n_estimators=10\n",
      "[0.0843478  0.06937288 0.04722976 0.10500569 0.08420277 0.08778964\n",
      " 0.09851328 0.09012433 0.10473973 0.08694547 0.0600661  0.08166256]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# Feature extraction, bind class to an object\n",
    "# n_estimators are the number of trees in the forest\n",
    "model1 = ExtraTreesClassifier(n_estimators=10)\n",
    "# Fit the arrays with the model\n",
    "model1.fit(X,y)\n",
    "print('The following is a scaled score of the features at n_estimators=10')\n",
    "print(model1.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a scaled score of the features at n_estimators=100\n",
      "[0.08328879 0.06851396 0.04960431 0.0956694  0.09280637 0.09481782\n",
      " 0.09852353 0.09762052 0.09489748 0.08169316 0.06113143 0.08143323]\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction, bind class to an object\n",
    "# n_estimators are the number of trees in the forest\n",
    "model2 = ExtraTreesClassifier(n_estimators=100)\n",
    "# Fit the arrays with the model\n",
    "model2.fit(X,y)\n",
    "print('The following is a scaled score of the features at n_estimators=100')\n",
    "print(model2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweets', 'isRetweet', 'isDeleted', 'avg_sentiment_score',\n",
       "       'sum_sentiment_score', 'delta_avg', 'retweets', 'favorites',\n",
       "       'word_count', 'positive', 'negative', 'neutral', 's&p_up/down'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature name</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>retweets</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.098524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>favorites</td>\n",
       "      <td>0.090124</td>\n",
       "      <td>0.097621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>avg_sentiment_score</td>\n",
       "      <td>0.105006</td>\n",
       "      <td>0.095669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>word_count</td>\n",
       "      <td>0.104740</td>\n",
       "      <td>0.094897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>delta_avg</td>\n",
       "      <td>0.087790</td>\n",
       "      <td>0.094818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>sum_sentiment_score</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.092806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0.084348</td>\n",
       "      <td>0.083289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.086945</td>\n",
       "      <td>0.081693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>isRetweet</td>\n",
       "      <td>0.069373</td>\n",
       "      <td>0.068514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.060066</td>\n",
       "      <td>0.061131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>isDeleted</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.049604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num         feature name      n=10     n=100\n",
       "6             7             retweets  0.098513  0.098524\n",
       "7             8            favorites  0.090124  0.097621\n",
       "3             4  avg_sentiment_score  0.105006  0.095669\n",
       "8             9           word_count  0.104740  0.094897\n",
       "5             6            delta_avg  0.087790  0.094818\n",
       "4             5  sum_sentiment_score  0.084203  0.092806\n",
       "0             1               tweets  0.084348  0.083289\n",
       "9            10             positive  0.086945  0.081693\n",
       "11           12              neutral  0.081663  0.081433\n",
       "1             2            isRetweet  0.069373  0.068514\n",
       "10           11             negative  0.060066  0.061131\n",
       "2             3            isDeleted  0.047230  0.049604"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank the outcomes by n_estimators 100\n",
    "feature_num = np.arange(1, 13, 1)\n",
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature name' : df.columns[0:-1],\n",
    "    'n=10' : model1.feature_importances_, \n",
    "    'n=100' : model2.feature_importances_}\n",
    "etc_rank = pd.DataFrame(dict)\n",
    "etc_rank.sort_values(by='n=100', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature name</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>avg_sentiment_score</td>\n",
       "      <td>0.105006</td>\n",
       "      <td>0.095669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>word_count</td>\n",
       "      <td>0.104740</td>\n",
       "      <td>0.094897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>retweets</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.098524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>favorites</td>\n",
       "      <td>0.090124</td>\n",
       "      <td>0.097621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>delta_avg</td>\n",
       "      <td>0.087790</td>\n",
       "      <td>0.094818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.086945</td>\n",
       "      <td>0.081693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tweets</td>\n",
       "      <td>0.084348</td>\n",
       "      <td>0.083289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>sum_sentiment_score</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.092806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>isRetweet</td>\n",
       "      <td>0.069373</td>\n",
       "      <td>0.068514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.060066</td>\n",
       "      <td>0.061131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>isDeleted</td>\n",
       "      <td>0.047230</td>\n",
       "      <td>0.049604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num         feature name      n=10     n=100\n",
       "3             4  avg_sentiment_score  0.105006  0.095669\n",
       "8             9           word_count  0.104740  0.094897\n",
       "6             7             retweets  0.098513  0.098524\n",
       "7             8            favorites  0.090124  0.097621\n",
       "5             6            delta_avg  0.087790  0.094818\n",
       "9            10             positive  0.086945  0.081693\n",
       "0             1               tweets  0.084348  0.083289\n",
       "4             5  sum_sentiment_score  0.084203  0.092806\n",
       "11           12              neutral  0.081663  0.081433\n",
       "1             2            isRetweet  0.069373  0.068514\n",
       "10           11             negative  0.060066  0.061131\n",
       "2             3            isDeleted  0.047230  0.049604"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank the outcomes by n_estimators 100\n",
    "feature_num = np.arange(1, 13, 1)\n",
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature name' : df.columns[0:-1],\n",
    "    'n=10' : model1.feature_importances_, \n",
    "    'n=100' : model2.feature_importances_}\n",
    "etc_rank = pd.DataFrame(dict)\n",
    "etc_rank.sort_values(by='n=10', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "The scikit-learn library provides the [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest) class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "\n",
    "Many different statistical test scan be used with this selection method. For example the ANOVA F-value method is appropriate for numerical inputs and categorical data, as we see in the Pima dataset. This can be used via the [f_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html) function. We will select the 4 best features using this method in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.369e+02 1.433e+03 1.159e+03 5.761e+02 7.936e+01 6.782e+01 6.782e+01\n",
      " 1.901e+01 8.222e+01 8.222e+01 2.233e+01 4.641e+01 6.841e-01 9.614e+01\n",
      " 1.158e+02 1.158e+02 2.781e+02 1.609e+00 1.609e+00 3.701e+00 5.724e+00\n",
      " 2.882e+00 2.767e+02 3.354e+00 6.785e+00 2.537e+00 2.318e+02 1.677e+02\n",
      " 1.332e+02 6.494e+02 4.999e+02 9.147e+01 8.711e+01 2.340e+02 1.968e+01\n",
      " 6.505e+01 2.490e+01 1.042e+02 4.267e+01 1.194e+01]\n",
      "[[0 0 0 0 81]\n",
      " [0 1 0 0 158]\n",
      " [0 1 0 0 157]\n",
      " [0 0 0 0 169]\n",
      " [0 0 0 0 189]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "test = SelectKBest(score_func=f_classif, k=5)\n",
    "fit = test.fit(X, y)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>fit_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>koi_fpflag_ss</td>\n",
       "      <td>1432.706256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>koi_fpflag_co</td>\n",
       "      <td>1159.458615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>koi_fpflag_nt</td>\n",
       "      <td>736.896271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>koi_steff_err1</td>\n",
       "      <td>649.421795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>koi_fpflag_ec</td>\n",
       "      <td>576.060340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>koi_steff_err2</td>\n",
       "      <td>499.942313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>koi_depth</td>\n",
       "      <td>278.062703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>koi_teq</td>\n",
       "      <td>276.736364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>koi_slogg_err2</td>\n",
       "      <td>234.049828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>koi_model_snr</td>\n",
       "      <td>231.814329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num    feature_name   fit_scores\n",
       "1             2   koi_fpflag_ss  1432.706256\n",
       "2             3   koi_fpflag_co  1159.458615\n",
       "0             1   koi_fpflag_nt   736.896271\n",
       "29           30  koi_steff_err1   649.421795\n",
       "3             4   koi_fpflag_ec   576.060340\n",
       "30           31  koi_steff_err2   499.942313\n",
       "16           17       koi_depth   278.062703\n",
       "22           23         koi_teq   276.736364\n",
       "33           34  koi_slogg_err2   234.049828\n",
       "26           27   koi_model_snr   231.814329"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature_name' : df.columns[1:],\n",
    "    'fit_scores' : fit.scores_\n",
    "    }\n",
    "etc_rank = pd.DataFrame(dict)\n",
    "etc_rank.sort_values(by='fit_scores', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
    "\n",
    "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
    "\n",
    "You can learn more about the [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) class in the scikit-learn documentation.\n",
    "\n",
    "The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 6\n",
      "Selected Features: [False False False False  True False False False False False False False\n",
      " False False False False False False False  True  True  True False False\n",
      " False False False False False  True False False False False False False\n",
      " False  True False False]\n",
      "Feature Ranking: [18 22 16 21  1 34 35  2 33 32 24 13 30 14 19 20 12  5  4  1  1  1  6 11\n",
      "  9 10  3 25  8  1  7 26 31 29 23 28 27  1 15 17]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 6)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>best_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>koi_period</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>koi_prad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>koi_prad_err1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>koi_prad_err2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>koi_steff_err1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>ra</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_num    feature_name  best_fit\n",
       "4             5      koi_period      True\n",
       "19           20        koi_prad      True\n",
       "20           21   koi_prad_err1      True\n",
       "21           22   koi_prad_err2      True\n",
       "29           30  koi_steff_err1      True\n",
       "37           38              ra      True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature_name' : df.columns[1:],\n",
    "    'best_fit' : fit.support_\n",
    "    }\n",
    "feature_rfe = pd.DataFrame(dict)\n",
    "is_true = feature_rfe['best_fit'] == True\n",
    "feature_rfe[is_true]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Principal Component Analysis\n",
    "[Principal Component Analysis](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/) (or PCA) uses linear algebra to transform the dataset into a compressed form.\n",
    "\n",
    "Generally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\n",
    "\n",
    "In the example below, we use PCA and select 3 principal components.\n",
    "\n",
    "Learn more about the [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) class in scikit-learn by reviewing the PCA API. Dive deeper into the math behind PCA on the [Principal Component Analysis Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis) article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.848 0.132 0.012]\n",
      "[[ 2.244e-09  6.082e-08  3.256e-08  5.484e-08 -1.247e-05 -4.111e-10\n",
      "   4.111e-10 -6.973e-06 -2.838e-10  2.838e-10 -5.801e-08 -3.463e-07\n",
      "   2.671e-08 -5.446e-07 -2.058e-08  2.058e-08 -2.576e-03 -2.651e-05\n",
      "   2.651e-05  3.852e-05  3.189e-06 -7.064e-06  1.770e-03  8.492e-01\n",
      "   2.500e-01 -4.651e-01 -3.421e-05 -2.340e-08 -2.165e-04 -7.142e-06\n",
      "   4.967e-06 -5.892e-07  1.670e-08  9.538e-09  1.599e-05  1.399e-06\n",
      "  -4.987e-06  5.539e-07 -2.887e-07 -4.588e-07]\n",
      " [-1.936e-07  2.211e-06 -6.481e-07 -3.522e-07 -9.176e-05 -6.029e-09\n",
      "   6.029e-09 -3.027e-05 -2.944e-08  2.944e-08  4.351e-08 -4.875e-06\n",
      "   9.046e-07  5.669e-06 -9.978e-07  9.978e-07  9.998e-01  1.436e-02\n",
      "  -1.436e-02  3.227e-05  5.025e-05  2.442e-06  8.199e-04  9.640e-04\n",
      "   7.649e-04 -3.366e-03  5.891e-03 -7.439e-07  1.210e-03  9.067e-05\n",
      "  -1.257e-04 -6.323e-08  1.727e-07 -2.656e-08 -9.706e-07 -1.100e-08\n",
      "  -4.614e-08  1.133e-06 -7.096e-07  3.119e-08]\n",
      " [-2.404e-07 -4.450e-07 -2.874e-07 -4.665e-07  7.899e-05  2.686e-09\n",
      "  -2.686e-09  3.736e-05  1.153e-08 -1.153e-08  3.012e-08  2.107e-06\n",
      "  -3.193e-07  1.479e-06  1.685e-07 -1.685e-07 -1.839e-03 -1.522e-04\n",
      "   1.522e-04 -3.679e-04 -6.447e-05  4.402e-05 -4.408e-03 -2.326e-01\n",
      "  -6.137e-01 -7.545e-01 -4.797e-06  2.738e-07  4.126e-04 -1.681e-05\n",
      "  -1.245e-05  1.977e-06 -1.941e-08  2.033e-08 -1.034e-05 -6.308e-06\n",
      "  -1.647e-05  2.123e-06 -6.707e-08  1.901e-06]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# Create an array from the values in the dataframe values\n",
    "array = df.values\n",
    "# Pull out features and labels from the columns with slice \n",
    "X= array[:, 1:]\n",
    "y= array[:, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
